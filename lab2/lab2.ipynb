{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "from types import FunctionType\n",
    "from math import erf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, learning_rate=0.1):\n",
    "        self.weights = np.zeros(n_inputs)\n",
    "        self.bias = 0\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return np.heaviside(self.weights @ inputs + self.bias, 0)\n",
    "    \n",
    "    def backward(self, inputs, error):\n",
    "        self.weights += self.learning_rate * error * inputs\n",
    "        self.bias += self.learning_rate * error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] -> 1.00\n",
      "Predicted -> 1.0\n",
      "[-1  2] -> 0.00\n",
      "Predicted -> 0.0\n"
     ]
    }
   ],
   "source": [
    "#PERCEPTRON\n",
    "\n",
    "inputs = np.array([[2, 3], [-1, 2]])\n",
    "outputs = np.array([1, 0])\n",
    "\n",
    "neuron = Perceptron(inputs.shape[1])\n",
    "\n",
    "#train\n",
    "for input, output in zip(inputs, outputs):\n",
    "    pred = neuron.forward(input)\n",
    "    error = output - pred    \n",
    "    neuron.backward(input, error)\n",
    "\n",
    "#test \n",
    "for input, output in zip(inputs, outputs):\n",
    "    pred = neuron.forward(input)\n",
    "    print(f\"{input} -> {output:.2f}\\nPredicted -> {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n_inputs: np.ndarray, \n",
    "                 learning_rate: float=0.1):\n",
    "        self.weights = np.random.uniform(-0.1, 0.1, size=n_inputs)\n",
    "        self.bias = np.random.uniform(-0.1, 0.1)\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def __call__(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        return self.weights @ inputs + self.bias\n",
    "    \n",
    "    def backward(self, inputs: np.ndarray, \n",
    "                 error: np.ndarray) -> None:\n",
    "        dC_dw = inputs.T * error\n",
    "        dC_db = np.sum(error)\n",
    "        self.weights -= self.learning_rate * dC_dw\n",
    "        self.bias -= self.learning_rate * dC_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return (2 / (1 + np.exp(-2 * x))) - 1\n",
    "\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + erf(x / 1.41421))\n",
    "\n",
    "def swish(x):\n",
    "    return x * sigmoid(x)\n",
    "\n",
    "def leakyrelu(x, negative_slope=0.01):\n",
    "    return np.where(x >= 0, x, negative_slope * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs: np.ndarray, outputs: np.ndarray, \n",
    "          epochs: int=100, lr: float=0.1, \n",
    "          activation: FunctionType=relu) -> None:\n",
    "    \n",
    "    model = Neuron(inputs.shape[1], learning_rate=lr)\n",
    "\n",
    "    for _ in tqdm.tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            pred = activation(model(input))\n",
    "            error = pred - output\n",
    "            model.backward(input, error)\n",
    "            total_loss += (model(input) - output) ** 2\n",
    "\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        pred = activation(model(input))\n",
    "        print(f\"{input} -> {output:.2f}\\nPredicted -> {pred:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42038657975649cb924c98c52f0e40ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] -> 0.00\n",
      "Predicted -> 0.00\n",
      "[0 1] -> 0.00\n",
      "Predicted -> 0.00\n",
      "[1 0] -> 0.00\n",
      "Predicted -> 0.00\n",
      "[1 1] -> 1.00\n",
      "Predicted -> 1.00\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 1000\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "train(X, y, epochs=EPOCH, lr=LEARNING_RATE, activation=relu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
