{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie g≈Çƒôbokie ‚Äì przetwarzanie tekstu ‚Äì laboratoria\n",
    "# 1. TF‚ÄìIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbi√≥r dokument√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ['Ala lubi zwierzƒôta i ma kota oraz psa!',\n",
    "             'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!',\n",
    "             'I Jan je≈∫dzi na rowerze.',\n",
    "             '2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym',\n",
    "             'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czego potrzebujemy?\n",
    "\n",
    "- Chcemy zamieniƒá teksty na zbi√≥r s≈Ç√≥w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùî Pytania\n",
    "\n",
    "- Czy do stokenizowania tekstu mo≈ºemy u≈ºyƒá `document.split(' ')`?\n",
    "- Jakie trudno≈õci mo≈ºemy napotkaƒá?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_cleaned(str_dirty):\n",
    "    punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    new_str = str_dirty.lower()\n",
    "    new_str = re.sub(' +', ' ', new_str)\n",
    "    for char in punctuation:\n",
    "        new_str = new_str.replace(char,'')\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document = get_str_cleaned(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ala lubi zwierzƒôta i ma kota oraz psa'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_str(document):\n",
    "    return document.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ala', 'lubi', 'zwierzƒôta', 'i', 'ma', 'kota', 'oraz', 'psa']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_str(sample_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_cleaned = [get_str_cleaned(document) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ala lubi zwierzƒôta i ma kota oraz psa',\n",
       " 'ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika',\n",
       " 'i jan je≈∫dzi na rowerze',\n",
       " '2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym',\n",
       " 'tomek lubi psy ma psa i je≈∫dzi na motorze i rowerze']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_tokenized = [tokenize_str(d) for d in documents_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ala', 'lubi', 'zwierzƒôta', 'i', 'ma', 'kota', 'oraz', 'psa'],\n",
       " ['ola', 'lubi', 'zwierzƒôta', 'oraz', 'ma', 'kota', 'a', 'tak≈ºe', 'chomika'],\n",
       " ['i', 'jan', 'je≈∫dzi', 'na', 'rowerze'],\n",
       " ['2', 'wojna', '≈õwiatowa', 'by≈Ça', 'wielkim', 'konfliktem', 'zbrojnym'],\n",
       " ['tomek',\n",
       "  'lubi',\n",
       "  'psy',\n",
       "  'ma',\n",
       "  'psa',\n",
       "  'i',\n",
       "  'je≈∫dzi',\n",
       "  'na',\n",
       "  'motorze',\n",
       "  'i',\n",
       "  'rowerze']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùî Pytania\n",
    "\n",
    "- Jaki jest nastƒôpny krok w celu stworzenia wekt√≥r√≥w TF lub TF‚ÄìIDF?\n",
    "- Jakie wielko≈õci bƒôdzie wektor TF lub TF‚ÄìIDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stworzenie s≈Çownika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for document in documents_tokenized:\n",
    "    for word in document:\n",
    "        vocabulary.append(word)\n",
    "vocabulary = sorted(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " 'a',\n",
       " 'ala',\n",
       " 'by≈Ça',\n",
       " 'chomika',\n",
       " 'i',\n",
       " 'jan',\n",
       " 'je≈∫dzi',\n",
       " 'konfliktem',\n",
       " 'kota',\n",
       " 'lubi',\n",
       " 'ma',\n",
       " 'motorze',\n",
       " 'na',\n",
       " 'ola',\n",
       " 'oraz',\n",
       " 'psa',\n",
       " 'psy',\n",
       " 'rowerze',\n",
       " 'tak≈ºe',\n",
       " 'tomek',\n",
       " 'wielkim',\n",
       " 'wojna',\n",
       " 'zbrojnym',\n",
       " 'zwierzƒôta',\n",
       " '≈õwiatowa']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.1** *(1 pkt)*\n",
    "\n",
    "Napisz funkcjƒô `word_to_index(word: str)`, kt√≥ra dla danego s≈Çowa zwraca wektor jednostkowy (*one-hot vector*) w postaci `numpy.array`.\n",
    "\n",
    "Przyjmij, ≈ºe s≈Çownik dany jest za pomocƒÖ zmiennej globalnej `vocabulary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(word: str) -> np.array:\n",
    "    return np.eye(len(vocabulary))[vocabulary.index(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index('psa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.2** *(1 pkt)*\n",
    "\n",
    "Napisz funkcjƒô, kt√≥ra zamienia listƒô s≈Ç√≥w na wektor TF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(document: list) -> np.array:\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for word in document:\n",
    "        if word in vocabulary:\n",
    "            vector[vocabulary.index(word)] += 1\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf(documents_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_vectorized = list()\n",
    "for document in documents_tokenized:\n",
    "    document_vector = tf(document)\n",
    "    documents_vectorized.append(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 2., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 0., 1., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.        , 5.        , 5.        , 5.        , 5.        ,\n",
       "       1.66666667, 5.        , 2.5       , 5.        , 2.5       ,\n",
       "       1.66666667, 1.66666667, 5.        , 2.5       , 5.        ,\n",
       "       2.5       , 2.5       , 5.        , 2.5       , 5.        ,\n",
       "       5.        , 5.        , 5.        , 5.        , 2.5       ,\n",
       "       5.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf = np.zeros(len(vocabulary))\n",
    "idf = len(documents_vectorized) / np.sum(np.array(documents_vectorized) != 0,axis=0)\n",
    "display(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.3** *(1 pkt)*\n",
    "\n",
    "Napisz funkcjƒô, kt√≥ra zwraca podobie≈Ñstwo kosinusowe miƒôdzy dwoma dokumentami w postaci zwektoryzowanej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(query: np.array, document: np.array) -> float:\n",
    "    return np.dot(query, document) / (np.linalg.norm(query) * np.linalg.norm(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_vectorized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_vectorized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5892556509887895"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(documents_vectorized[0], documents_vectorized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosta wyszukiwarka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(query):\n",
    "    \"\"\"Funkcja, kt√≥ra czy≈õci i tokenizuje zapytanie\"\"\"\n",
    "    query_vector = tf(tokenize_str(get_str_cleaned(query)))\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(transform_query('psa kota'), documents_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2357022603955158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.19611613513818402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = 'psa kota'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4472135954999579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2773500981126146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dlatego potrzebujemy mianownik w cosine similarity\n",
    "query = 'rowerze'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.35355339059327373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4472135954999579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5547001962252291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dlatego potrzebujemy term frequency ‚Üí wiecej znaczy bardziej dopasowany dokument\n",
    "query = 'i'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.24999999999999994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2357022603955158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.31622776601683794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.39223227027636803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dlatego IDF - ≈ºeby wa≈ºniejsze s≈Çowa mia≈Ç wiƒôkszƒÖ wagƒô\n",
    "query = 'i chomika'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naiwne przeszukiwanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = list() \n",
    "for document in newsgroups:\n",
    "    if 'car' in document:\n",
    "        all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùî Pytanie\n",
    "\n",
    "Jakie sƒÖ problemy z takim podej≈õciem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF‚ÄìIDF i odleg≈Ço≈õƒá kosinusowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vectors = vectorizer.fit_transform(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 89 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors[0].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors[0:4].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = 'speed'\n",
    "#query_str = 'speed car'\n",
    "#query_str = 'spider man'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26949927 0.3491801  0.44292083 0.47784165]\n",
      "[4517 5509 2116 9921]\n",
      "From: ray@netcom.com (Ray Fischer)\n",
      "Subject: Re: x86 ~= 680x0 ??  (How do they compare?)\n",
      "Organization: Netcom. San Jose, California\n",
      "Distribution: usa\n",
      "Lines: 36\n",
      "\n",
      "dhk@ubbpc.uucp (Dave Kitabjian) writes ...\n",
      ">I'm sure Intel and Motorola are competing neck-and-neck for \n",
      ">crunch-power, but for a given clock speed, how do we rank the\n",
      ">following (from 1st to 6th):\n",
      ">  486\t\t68040\n",
      ">  386\t\t68030\n",
      ">  286\t\t68020\n",
      "\n",
      "040 486 030 386 020 286\n",
      "\n",
      ">While you're at it, where will the following fit into the list:\n",
      ">  68060\n",
      ">  Pentium\n",
      ">  PowerPC\n",
      "\n",
      "060 fastest, then Pentium, with the first versions of the PowerPC\n",
      "somewhere in the vicinity.\n",
      "\n",
      ">And about clock speed:  Does doubling the clock speed double the\n",
      ">overall processor speed?  And fill in the __'s below:\n",
      ">  68030 @ __ MHz = 68040 @ __ MHz\n",
      "\n",
      "No.  Computer speed is only partly dependent of processor/clock speed.\n",
      "Memory system speed play a large role as does video system speed and\n",
      "I/O speed.  As processor clock rates go up, the speed of the memory\n",
      "system becomes the greatest factor in the overall system speed.  If\n",
      "you have a 50MHz processor, it can be reading another word from memory\n",
      "every 20ns.  Sure, you can put all 20ns memory in your computer, but\n",
      "it will cost 10 times as much as the slower 80ns SIMMs.\n",
      "\n",
      "And roughly, the 68040 is twice as fast at a given clock\n",
      "speed as is the 68030.\n",
      "\n",
      "-- \n",
      "Ray Fischer                   \"Convictions are more dangerous enemies of truth\n",
      "ray@netcom.com                 than lies.\"  -- Friedrich Nietzsche\n",
      "\n",
      "0.4778416465020907\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From: rvenkate@ux4.cso.uiuc.edu (Ravikuma Venkateswar)\n",
      "Subject: Re: x86 ~= 680x0 ?? (How do they compare?)\n",
      "Distribution: usa\n",
      "Organization: University of Illinois at Urbana\n",
      "Lines: 59\n",
      "\n",
      "ray@netcom.com (Ray Fischer) writes:\n",
      "\n",
      ">dhk@ubbpc.uucp (Dave Kitabjian) writes ...\n",
      ">>I'm sure Intel and Motorola are competing neck-and-neck for \n",
      ">>crunch-power, but for a given clock speed, how do we rank the\n",
      ">>following (from 1st to 6th):\n",
      ">>  486\t\t68040\n",
      ">>  386\t\t68030\n",
      ">>  286\t\t68020\n",
      "\n",
      ">040 486 030 386 020 286\n",
      "\n",
      "How about some numbers here? Some kind of benchmark?\n",
      "If you want, let me start it - 486DX2-66 - 32 SPECint92, 16 SPECfp92 .\n",
      "\n",
      ">>While you're at it, where will the following fit into the list:\n",
      ">>  68060\n",
      ">>  Pentium\n",
      ">>  PowerPC\n",
      "\n",
      ">060 fastest, then Pentium, with the first versions of the PowerPC\n",
      ">somewhere in the vicinity.\n",
      "\n",
      "Numbers? Pentium @66MHz - 65 SPECint92, 57 SPECfp92 .\n",
      "\t PowerPC @66MHz - 50 SPECint92, 80 SPECfp92 . (Note this is the 601)\n",
      "        (Alpha @150MHz  - 74 SPECint92,126 SPECfp92 - just for comparison)\n",
      "\n",
      ">>And about clock speed:  Does doubling the clock speed double the\n",
      ">>overall processor speed?  And fill in the __'s below:\n",
      ">>  68030 @ __ MHz = 68040 @ __ MHz\n",
      "\n",
      ">No.  Computer speed is only partly dependent of processor/clock speed.\n",
      ">Memory system speed play a large role as does video system speed and\n",
      ">I/O speed.  As processor clock rates go up, the speed of the memory\n",
      ">system becomes the greatest factor in the overall system speed.  If\n",
      ">you have a 50MHz processor, it can be reading another word from memory\n",
      ">every 20ns.  Sure, you can put all 20ns memory in your computer, but\n",
      ">it will cost 10 times as much as the slower 80ns SIMMs.\n",
      "\n",
      "Not in a clock-doubled system. There isn't a doubling in performance, but\n",
      "it _is_ quite significant. Maybe about a 70% increase in performance.\n",
      "\n",
      "Besides, for 0 wait state performance, you'd need a cache anyway. I mean,\n",
      "who uses a processor that runs at the speed of 80ns SIMMs? Note that this\n",
      "memory speed corresponds to a clock speed of 12.5 MHz.\n",
      "\n",
      ">And roughly, the 68040 is twice as fast at a given clock\n",
      ">speed as is the 68030.\n",
      "\n",
      "Numbers?\n",
      "\n",
      ">-- \n",
      ">Ray Fischer                   \"Convictions are more dangerous enemies of truth\n",
      ">ray@netcom.com                 than lies.\"  -- Friedrich Nietzsche\n",
      "-- \n",
      "Ravikumar Venkateswar\n",
      "rvenkate@uiuc.edu\n",
      "\n",
      "A pun is a no' blessed form of whit.\n",
      "\n",
      "0.44292082969477664\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From: ray@netcom.com (Ray Fischer)\n",
      "Subject: Re: x86 ~= 680x0 ?? (How do they compare?)\n",
      "Organization: Netcom. San Jose, California\n",
      "Distribution: usa\n",
      "Lines: 30\n",
      "\n",
      "rvenkate@ux4.cso.uiuc.edu (Ravikuma Venkateswar) writes ...\n",
      ">ray@netcom.com (Ray Fischer) writes:\n",
      ">>040 486 030 386 020 286\n",
      ">\n",
      ">How about some numbers here? Some kind of benchmark?\n",
      "\n",
      "Benchmarks are for marketing dweebs and CPU envy.  OK, if it will make\n",
      "you happy, the 486 is faster than the 040.  BFD.  Both architectures\n",
      "are nearing then end of their lifetimes.  And especially with the x86\n",
      "architecture: good riddance.\n",
      "\n",
      ">Besides, for 0 wait state performance, you'd need a cache anyway. I mean,\n",
      ">who uses a processor that runs at the speed of 80ns SIMMs? Note that this\n",
      ">memory speed corresponds to a clock speed of 12.5 MHz.\n",
      "\n",
      "The point being the processor speed is only one of many aspects of a\n",
      "computers performance.  Clock speed, processor, memory speed, CPU\n",
      "architecture, I/O systems, even the application program all contribute \n",
      "to the overall system performance.\n",
      "\n",
      ">>And roughly, the 68040 is twice as fast at a given clock\n",
      ">>speed as is the 68030.\n",
      ">\n",
      ">Numbers?\n",
      "\n",
      "Look them up yourself.\n",
      "\n",
      "-- \n",
      "Ray Fischer                   \"Convictions are more dangerous enemies of truth\n",
      "ray@netcom.com                 than lies.\"  -- Friedrich Nietzsche\n",
      "\n",
      "0.3491800997095306\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From: mb4008@cehp11 (Morgan J Bullard)\n",
      "Subject: Re: speeding up windows\n",
      "Keywords: speed\n",
      "Organization: University of Illinois at Urbana\n",
      "Lines: 30\n",
      "\n",
      "djserian@flash.LakeheadU.Ca (Reincarnation of Elvis) writes:\n",
      "\n",
      ">I have a 386/33 with 8 megs of memory\n",
      "\n",
      ">I have noticed that lately when I use programs like WpfW or Corel Draw\n",
      ">my computer \"boggs\" down and becomes really sluggish!\n",
      "\n",
      ">What can I do to increase performance?  What should I turn on or off\n",
      "\n",
      ">Will not loading wallpapers or stuff like that help when it comes to\n",
      ">the running speed of windows and the programs that run under it?\n",
      "\n",
      ">Thanx in advance\n",
      "\n",
      ">Derek\n",
      "\n",
      "1) make sure your hard drive is defragmented. This will speed up more than \n",
      "   just windows BTW.  Use something like Norton's or PC Tools.\n",
      "2) I _think_ that leaving the wall paper out will use less RAM and therefore\n",
      "   will speed up your machine but I could very will be wrong on this.\n",
      "There's a good chance you've already done this but if not it may speed things\n",
      "up.  good luck\n",
      "\t\t\t\tMorgan Bullard mb4008@coewl.cen.uiuc.edu\n",
      "\t\t\t\t\t  or   mjbb@uxa.cso.uiuc.edu\n",
      "\n",
      ">--\n",
      ">$_    /|$Derek J.P. Serianni $ E-Mail : djserian@flash.lakeheadu.ca           $ \n",
      ">$\\'o.O' $Sociologist         $ It's 106 miles to Chicago,we've got a full tank$\n",
      ">$=(___)=$Lakehead University $ of gas, half a pack of cigarettes,it's dark,and$\n",
      ">$   U   $Thunder Bay, Ontario$ we're wearing sunglasses. -Elwood Blues        $  \n",
      "\n",
      "0.26949927393886913\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query_vector = vectorizer.transform([query_str])\n",
    "similarities = sklearn.metrics.pairwise.cosine_similarity(query_vector,document_vectors)\n",
    "print(np.sort(similarities)[0][-4:])\n",
    "print(similarities.argsort()[0][-4:])\n",
    "\n",
    "for i in range (1,5):\n",
    "    print(newsgroups[similarities.argsort()[0][-i]])\n",
    "    print(np.sort(similarities)[0,-i])\n",
    "    print('-'*100)\n",
    "    print('-'*100)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.4** *(4 pkt.)*\n",
    "\n",
    "Wybierz zbi√≥r tekstowy, kt√≥ry ma conajmniej 10000 dokument√≥w (inny ni≈º w tym przyk≈Çadzie).\n",
    "Na jego podstawie stw√≥rz wyszukiwarkƒô wykorzystujƒÖcƒÖ TF‚ÄìIDF i podobie≈Ñstwo kosinusowe do oceny podobie≈Ñstwa dokument√≥w. Wyszukiwarka powinna zwracaƒá kilka posortowanych najbardziej pasujƒÖcych dokument√≥w razem ze score'ami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(corpus: list, corpus_vectors: np.ndarray, \n",
    "           query: str, n: int=4):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = sklearn.metrics.pairwise.cosine_similarity(query_vector,corpus_vectors)\n",
    "    \n",
    "    for i in range (1, n+1):\n",
    "        print(corpus[similarities.argsort()[0][-i]])\n",
    "        print(np.sort(similarities)[0,-i])\n",
    "        print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SWPS University has entered into cooperation with Marshall University (MU), University of Debrecen (DU), California State University Stanislaus (CSUS) and Bangor University (BU).\n",
      "\n",
      "0.47042171958188805\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ÔÇ∑ University Strategy,\n",
      "\n",
      "0.41675248793039\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ÔÇ∑ University Statute,\n",
      "\n",
      "0.39494577452264923\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Current practices of the SWPS University The University has established a Scientific Research Office (Biuro ds.\n",
      "\n",
      "0.3106022718147999\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Current practices of the SWPS University\n",
      "\n",
      "0.2983536024169672\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Data from https://opus.nlpl.eu/ELRC-3855-SWPS_University_Soci/pl&en/v1/ELRC-3855-SWPS_University_Soci\n",
    "with open(\"en.txt\", encoding=\"utf8\") as text_file:\n",
    "    corpus = [line for line in text_file]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus_vectors = vectorizer.fit_transform(corpus)\n",
    "\n",
    "search(corpus, corpus_vectors, 'University', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
