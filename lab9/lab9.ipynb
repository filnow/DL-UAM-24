{"cells":[{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:30.191159Z","iopub.status.busy":"2024-06-01T11:46:30.190792Z","iopub.status.idle":"2024-06-01T11:46:30.200466Z","shell.execute_reply":"2024-06-01T11:46:30.199343Z","shell.execute_reply.started":"2024-06-01T11:46:30.191130Z"},"trusted":true},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","\n","from nltk.translate.bleu_score import corpus_bleu\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:30.202323Z","iopub.status.busy":"2024-06-01T11:46:30.202027Z","iopub.status.idle":"2024-06-01T11:46:30.219039Z","shell.execute_reply":"2024-06-01T11:46:30.218116Z","shell.execute_reply.started":"2024-06-01T11:46:30.202300Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:30.220905Z","iopub.status.busy":"2024-06-01T11:46:30.220621Z","iopub.status.idle":"2024-06-01T11:46:30.228702Z","shell.execute_reply":"2024-06-01T11:46:30.227829Z","shell.execute_reply.started":"2024-06-01T11:46:30.220877Z"},"trusted":true},"outputs":[],"source":["SOS_token = 0\n","EOS_token = 1\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:30.230374Z","iopub.status.busy":"2024-06-01T11:46:30.229942Z","iopub.status.idle":"2024-06-01T11:46:30.236969Z","shell.execute_reply":"2024-06-01T11:46:30.236161Z","shell.execute_reply.started":"2024-06-01T11:46:30.230344Z"},"trusted":true},"outputs":[],"source":["def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    #NOTE: added polish character replacement that is not in the original code\n","    s = re.sub(r'Å‚', 'l', s)\n","    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n","    return s.strip()"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:30.239106Z","iopub.status.busy":"2024-06-01T11:46:30.238856Z","iopub.status.idle":"2024-06-01T11:46:30.248043Z","shell.execute_reply":"2024-06-01T11:46:30.247194Z","shell.execute_reply.started":"2024-06-01T11:46:30.239085Z"},"trusted":true},"outputs":[],"source":["def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('/kaggle/input/eng-pol/eng-pol.txt', encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:30.249500Z","iopub.status.busy":"2024-06-01T11:46:30.249130Z","iopub.status.idle":"2024-06-01T11:46:30.256099Z","shell.execute_reply":"2024-06-01T11:46:30.255326Z","shell.execute_reply.started":"2024-06-01T11:46:30.249453Z"},"trusted":true},"outputs":[],"source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s \",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:30.257264Z","iopub.status.busy":"2024-06-01T11:46:30.256997Z","iopub.status.idle":"2024-06-01T11:46:32.648154Z","shell.execute_reply":"2024-06-01T11:46:32.647229Z","shell.execute_reply.started":"2024-06-01T11:46:30.257239Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading lines...\n","Read 49943 sentence pairs\n","Trimmed to 3617 sentence pairs\n","Counting words...\n","Counted words:\n","pol 3111\n","eng 1973\n","['jest bardzo prawdopodobne ze sie spozni', 'he s very likely to be late']\n"]}],"source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'pol', True)\n","print(random.choice(pairs))"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.651015Z","iopub.status.busy":"2024-06-01T11:46:32.650665Z","iopub.status.idle":"2024-06-01T11:46:32.657441Z","shell.execute_reply":"2024-06-01T11:46:32.656576Z","shell.execute_reply.started":"2024-06-01T11:46:32.650984Z"},"trusted":true},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, input):\n","        embedded = self.dropout(self.embedding(input))\n","        output, hidden = self.gru(embedded)\n","        return output, hidden"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.658742Z","iopub.status.busy":"2024-06-01T11:46:32.658478Z","iopub.status.idle":"2024-06-01T11:46:32.669973Z","shell.execute_reply":"2024-06-01T11:46:32.669120Z","shell.execute_reply.started":"2024-06-01T11:46:32.658720Z"},"trusted":true},"outputs":[],"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n","        batch_size = encoder_outputs.size(0)\n","        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n","        decoder_hidden = encoder_hidden\n","        decoder_outputs = []\n","\n","        for i in range(MAX_LENGTH):\n","            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n","            decoder_outputs.append(decoder_output)\n","\n","            if target_tensor is not None:\n","                decoder_input = target_tensor[:, i].unsqueeze(1) \n","            else:\n","                _, topi = decoder_output.topk(1)\n","                decoder_input = topi.squeeze(-1).detach()  \n","\n","        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n","        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n","        return decoder_outputs, decoder_hidden, None \n","\n","    def forward_step(self, input, hidden):\n","        output = self.embedding(input)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.out(output)\n","        return output, hidden"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.671776Z","iopub.status.busy":"2024-06-01T11:46:32.671412Z","iopub.status.idle":"2024-06-01T11:46:32.687414Z","shell.execute_reply":"2024-06-01T11:46:32.686542Z","shell.execute_reply.started":"2024-06-01T11:46:32.671748Z"},"trusted":true},"outputs":[],"source":["class BahdanauAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(BahdanauAttention, self).__init__()\n","        self.Wa = nn.Linear(hidden_size, hidden_size)\n","        self.Ua = nn.Linear(hidden_size, hidden_size)\n","        self.Va = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, query, keys):\n","        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n","        scores = scores.squeeze(2).unsqueeze(1)\n","\n","        weights = F.softmax(scores, dim=-1)\n","        context = torch.bmm(weights, keys)\n","\n","        return context, weights\n","\n","class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.attention = BahdanauAttention(hidden_size)\n","        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n","        batch_size = encoder_outputs.size(0)\n","        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n","        decoder_hidden = encoder_hidden\n","        decoder_outputs = []\n","        attentions = []\n","\n","        for i in range(MAX_LENGTH):\n","            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            decoder_outputs.append(decoder_output)\n","            attentions.append(attn_weights)\n","\n","            if target_tensor is not None:\n","                decoder_input = target_tensor[:, i].unsqueeze(1) \n","            else:\n","                _, topi = decoder_output.topk(1)\n","                decoder_input = topi.squeeze(-1).detach()  \n","\n","        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n","        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n","        attentions = torch.cat(attentions, dim=1)\n","\n","        return decoder_outputs, decoder_hidden, attentions\n","\n","\n","    def forward_step(self, input, hidden, encoder_outputs):\n","        embedded =  self.dropout(self.embedding(input))\n","\n","        query = hidden.permute(1, 0, 2)\n","        context, attn_weights = self.attention(query, encoder_outputs)\n","        input_gru = torch.cat((embedded, context), dim=2)\n","\n","        output, hidden = self.gru(input_gru, hidden)\n","        output = self.out(output)\n","\n","        return output, hidden, attn_weights"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.688811Z","iopub.status.busy":"2024-06-01T11:46:32.688493Z","iopub.status.idle":"2024-06-01T11:46:32.700991Z","shell.execute_reply":"2024-06-01T11:46:32.700130Z","shell.execute_reply.started":"2024-06-01T11:46:32.688781Z"},"trusted":true},"outputs":[],"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)\n","\n","def get_dataloader(batch_size, test_size=0.2):\n","    input_lang, output_lang, pairs = prepareData('eng', 'pol', True)\n","\n","    n = len(pairs)\n","    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n","    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n","\n","    for idx, (inp, tgt) in enumerate(pairs):\n","        inp_ids = indexesFromSentence(input_lang, inp)\n","        tgt_ids = indexesFromSentence(output_lang, tgt)\n","        inp_ids.append(EOS_token)\n","        tgt_ids.append(EOS_token)\n","        input_ids[idx, :len(inp_ids)] = inp_ids\n","        target_ids[idx, :len(tgt_ids)] = tgt_ids\n","\n","    # Split the data into training and test sets\n","    input_ids_train, input_ids_test, target_ids_train, target_ids_test = train_test_split(\n","        input_ids, target_ids, test_size=test_size\n","    )\n","\n","    train_data = TensorDataset(torch.LongTensor(input_ids_train).to(device),\n","                               torch.LongTensor(target_ids_train).to(device))\n","    test_data = TensorDataset(torch.LongTensor(input_ids_test).to(device),\n","                              torch.LongTensor(target_ids_test).to(device))\n","\n","    train_sampler = RandomSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","    test_sampler = RandomSampler(test_data)\n","    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","\n","    return input_lang, output_lang, train_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.702436Z","iopub.status.busy":"2024-06-01T11:46:32.702100Z","iopub.status.idle":"2024-06-01T11:46:32.712801Z","shell.execute_reply":"2024-06-01T11:46:32.711977Z","shell.execute_reply.started":"2024-06-01T11:46:32.702407Z"},"trusted":true},"outputs":[],"source":["def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n","          decoder_optimizer, criterion):\n","\n","    total_loss = 0\n","    for data in dataloader:\n","        input_tensor, target_tensor = data\n","\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","\n","        encoder_outputs, encoder_hidden = encoder(input_tensor)\n","        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n","\n","        loss = criterion(\n","            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n","            target_tensor.view(-1)\n","        )\n","        loss.backward()\n","\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    return total_loss / len(dataloader)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.714267Z","iopub.status.busy":"2024-06-01T11:46:32.713923Z","iopub.status.idle":"2024-06-01T11:46:32.723471Z","shell.execute_reply":"2024-06-01T11:46:32.722630Z","shell.execute_reply.started":"2024-06-01T11:46:32.714238Z"},"trusted":true},"outputs":[],"source":["import time\n","import math\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.726169Z","iopub.status.busy":"2024-06-01T11:46:32.725891Z","iopub.status.idle":"2024-06-01T11:46:32.734560Z","shell.execute_reply":"2024-06-01T11:46:32.733753Z","shell.execute_reply.started":"2024-06-01T11:46:32.726146Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.735945Z","iopub.status.busy":"2024-06-01T11:46:32.735640Z","iopub.status.idle":"2024-06-01T11:46:32.744956Z","shell.execute_reply":"2024-06-01T11:46:32.744040Z","shell.execute_reply.started":"2024-06-01T11:46:32.735915Z"},"trusted":true},"outputs":[],"source":["def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n","               print_every=100, plot_every=100):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  \n","    plot_loss_total = 0  \n","\n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss()\n","\n","    for epoch in range(1, n_epochs + 1):\n","        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if epoch % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n","                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n","\n","        if epoch % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.746449Z","iopub.status.busy":"2024-06-01T11:46:32.746079Z","iopub.status.idle":"2024-06-01T11:46:32.757240Z","shell.execute_reply":"2024-06-01T11:46:32.756365Z","shell.execute_reply.started":"2024-06-01T11:46:32.746420Z"},"trusted":true},"outputs":[],"source":["def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","\n","        encoder_outputs, encoder_hidden = encoder(input_tensor)\n","        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n","\n","        _, topi = decoder_outputs.topk(1)\n","        decoded_ids = topi.squeeze()\n","\n","        decoded_words = []\n","        for idx in decoded_ids:\n","            if idx.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            decoded_words.append(output_lang.index2word[idx.item()])\n","    return decoded_words, decoder_attn\n","\n","def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')\n","        \n","def evaluateBleu(encoder, decoder, pairs, n=100):\n","    candidate_corpus = []\n","    references_corpus = []\n","    for pair in pairs:\n","        candidate_corpus.append(pair[1].split(\" \"))\n","        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n","        output_sentence = ' '.join(output_words[:-1])\n","        references_corpus.append(output_sentence.split(\" \"))\n","\n","    return corpus_bleu(candidate_corpus, references_corpus)\n","        "]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-06-01T11:46:32.758564Z","iopub.status.busy":"2024-06-01T11:46:32.758299Z","iopub.status.idle":"2024-06-01T11:50:57.139966Z","shell.execute_reply":"2024-06-01T11:50:57.138555Z","shell.execute_reply.started":"2024-06-01T11:46:32.758541Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading lines...\n","Read 49943 sentence pairs\n","Trimmed to 3617 sentence pairs\n","Counting words...\n","Counted words:\n","pol 3111\n","eng 1973\n","0m 16s (- 3m 45s) (10 6%) 1.7731\n","0m 32s (- 3m 28s) (20 13%) 0.7863\n","0m 48s (- 3m 12s) (30 20%) 0.3547\n","1m 4s (- 2m 56s) (40 26%) 0.1419\n","1m 20s (- 2m 40s) (50 33%) 0.0636\n","1m 36s (- 2m 24s) (60 40%) 0.0385\n","1m 52s (- 2m 8s) (70 46%) 0.0279\n","2m 8s (- 1m 52s) (80 53%) 0.0237\n","2m 24s (- 1m 36s) (90 60%) 0.0205\n","2m 40s (- 1m 20s) (100 66%) 0.0182\n","2m 56s (- 1m 4s) (110 73%) 0.0161\n","3m 12s (- 0m 48s) (120 80%) 0.0168\n","3m 28s (- 0m 32s) (130 86%) 0.0155\n","3m 44s (- 0m 16s) (140 93%) 0.0143\n","4m 0s (- 0m 0s) (150 100%) 0.0150\n","> nie jestem pewien jak postepowac\n","= i m not sure how to proceed\n","< i m not sure how like begin like not remember\n","\n","> jestem troche oszolomiony\n","= i m a little dizzy\n","< i m a little dizzy <EOS>\n","\n","> nawet nie probujesz\n","= you aren t even trying\n","< you aren t even trying not afraid not yet <EOS>\n","\n","> jestem prosta dziewczyna\n","= i m a simple girl\n","< i m a simple girl <EOS>\n","\n","> zarazasz\n","= you re contagious\n","< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n","\n","> stoisz mi na drodze\n","= you are in my way\n","< you are in my way <EOS>\n","\n","> prawie skonczylem sprawozdanie\n","= i m just about finished with the report\n","< i m just about finished with the report students <EOS>\n","\n","> nie mam utartych przyzwyczajen\n","= i m not a creature of habit\n","< i m not a creature of habit not habit <EOS>\n","\n","> jestem pewien ze jutro sobie lepiej poradzimy\n","= i m sure we ll do better tomorrow\n","< i m sure tom will questions questions <EOS>\n","\n","> on nie jest durniem\n","= he is not stupid\n","< he s not ready yet <EOS>\n","\n","\n","Bleu score: 0.14487126938042572\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]}],"source":["hidden_size = 128\n","batch_size = 32\n","\n","input_lang, output_lang, train_dataloader, test_dataloader = get_dataloader(batch_size)\n","\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n","\n","train(train_dataloader, encoder, decoder, 150, print_every=10, plot_every=10)\n","\n","encoder.eval()\n","decoder.eval()\n","\n","evaluateRandomly(encoder, decoder)\n","score = evaluateBleu(encoder, decoder, pairs)\n","\n","print(f\"\\nBleu score: {score}\\n\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5128385,"sourceId":8576205,"sourceType":"datasetVersion"}],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
