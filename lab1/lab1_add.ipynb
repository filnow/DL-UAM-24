{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## 1. Funkcja kosztu\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\n",
    "Błąd modelu (czyli funkcja kosztu) powinien  być dobrym estymatorem jakości modelu budowanego na ustalonych  danych. W sekcji tej wyjaśnimy dokładnie tylko jedną koncepcję uczenia maszynowego, gdyż jest ona stosowana w typowych modelach regresyjnych.  Szczegóły pozostałych podejść do tego zagadnienia takie jak SVM, knn, drzewa decyzyjne, PCA oraz metoda k-średnich można znaleźć w klasycznej literaturze dotyczącej uczenia maszynowego.\n",
    "\n",
    "Załóżmy, że rozpatrujemy zbiór danych wygenerowanych niezależnie $(x_1,x_2,\\dots,x_m)$. Naturalne jest założenie, że rozkład prawdopodobieństwa $p_{data}(x)$ tych danych  jest jednakowy, tzn. dla każdego $i\\not = j$ $p_{data}(x_i)=p_{data}(x_j)$. Mówimy wtedy, że dane są $i.i.d.$ (independent identically distributed).  Załóżmy, że celem jest estymacja parametru $\\theta$ (w regresji liniowej, logistycznej  oraz w sieciach neuronowych $\\theta$ jest wektorem wszystkich wag). Teoretycznym estymatorem tego parametru jest każda funkcja $\\hat{\\theta}_m = g(x_1,x_2,\\dots,x_m)$. Jest to zmienna losowa, gdyż dane traktujemy jako wylosowane. Rozkład $p_{data}$ jest oczywiście nieznany, gdyż inaczej budowanie modelu byłoby bezcelowe. Zwykle jednak zakładamy, że rozkład danych należy do pewnej klasy rozkładów o nieznanych parametrach $\\theta$ rozkładu. Przykładowo dla danej $x$, o której zakładamy, że jest próbką z rozkładu normalnego parametr $\\theta$ jest dwuwymiarowy:\n",
    "$\\theta=(\\mu,\\sigma)$. \n",
    "Model możemy zatem traktować jako estymator nieznanego rozkładu danych  opracowany na próbce takich danych (skończonym podzbiorze, który znamy). Oznaczmy przez $p_{model}(x;\\theta)$ prawdopodobieństwo rozkładu estymującego za pomocą modelu  rzeczywisty nieznany rozkład $p_{data}(x)$ dla ustalonej próbki $x$. Im takie prawdopodobieństwo  rozkładu modelu dla ustalonej próbki będzie wyższe, tym lepiej model będzie reprezentował tą próbkę. Rozpatrując wszystkie $m$ próbek jednocześnie  musimy rozpatrywać ich prawdopodobieństwo wspólne, tzn. $p_{model}(x_1,x_2,\\dots,x_m; \\theta)$. Z niezależności próbek dostajemy, że \n",
    "\n",
    "$$p_{model}(x_1,x_2,\\dots,x_m; \\theta)= p_{model}(x_1;\\theta)\\cdot \\dots p_{model}(x_m;\\theta) = \\prod_{i=1}^m p_{model}(x_i; \\theta)$$. \\\\\n",
    "\n",
    "\\noindent Te rozważania prowadzą do zdefiniowania funkcji nazywanej \\textit{ funkcją wiarygodności estymatora z parametrem $\\theta$}:\n",
    "$$l(\\theta) = K\\cdot\\prod_{i=1}^m p_{model}(x_i;\\theta),$$\n",
    "gdzie $K$ jest pewną stałą -  współczynnikiem proporcjonalności. \\textit{Estymatorem największej wiarygodności parametru} $\\theta$ przy ustalonych danych $x_1,x_2,\\dots,x_m$ nazywamy taką\n",
    "funkcję wiarygodności $l(\\hat{\\theta})$,  że\n",
    "$$\n",
    "l(\\hat{\\theta})= \\max_{\\theta}l(\\theta).\n",
    "$$\n",
    "\n",
    "Równoważnie\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} =arg\\ \\max_{\\theta}l(\\theta) = arg\\ \\max_{\\theta} \\prod_{i=1}^m p_{model}(x_i;\\theta).\n",
    "$$\n",
    "\n",
    "\n",
    "W związku z tym, że każdy czynnik w iloczynie prawdopodobieństw jest nieujemnym ułamkiem mniejszym od 1, numeryka takiego iloczynu implikuje zagrożenie niedomiarem \n",
    "zmiennoprzecinkowym.  Możemy to zagrożenie usunąć korzystając z prostego faktu:\n",
    "\n",
    "##### Fakt pomocniczy:\n",
    "Niech $0>a>b$.  Niech $f:[a,b]\\rightarrow\\mathbb{R}$, $g:\\mathbb{R}\\rightarrow\\mathbb{R}$ będą ciągłe na $[a,b]$ oraz $g(x)=ln(f(x))$ dla $x\\in \\mathbb{R}$. Wtedy funkcje $f$ oraz $g$ osiągają wartości ekstremalne w tych  w tych \n",
    "samych punktach.\n",
    "\n",
    "\n",
    "\\textbf{Uzasadnienie}: Z ciągłości i zwartości przedziału $[a,b]$ dostajemy, że $f$ i $g$ osiągają ekstrema na $[a,b]$. $g'(x) = (ln(f(x)))' = \\frac{f'(x)}{f(x)}$. \n",
    "Wtedy jeżeli $g'(x)$ istnieje oraz  $g'(x)=0$, to $f'(x)=0$, co kończy dowód.    \n",
    "\n",
    "Tak sformułowany Fakt pomocniczy pozwala zadanie maksymalizacji funkcji wiarygodności zastąpić  zadaniem maksymalizacji logarytmu tej funkcji:\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\theta} &=& arg\\ \\max_{\\theta} \\prod_{i=1}^m p_{model}(x_i;\\theta) =arg\\  \\max_{\\theta} log\\,\\left(\\prod_{i=1}^m p_{model}(x_i;\\theta).\\right) \\nonumber \\\\\n",
    "&=& arg\\ \\max_{\\theta} \\sum_{i=1}^m log(p_{model}(x_i;\\theta)\\label{eq:ml2}\n",
    "\\end{eqnarray}\n",
    "  \n",
    "Logarytmiczna formuła estymatora największej wiarygodności nie jest już niebezpieczna ze względu na niedomiar zmiennoprzecinkowy. Definiując rozkład empiryczny zbioru próbek\n",
    "jako\n",
    "$$\n",
    "\\hat{p}_{data}(x) = \\frac{1}{m}\\sum_{i=1}^m x_i\n",
    "$$\n",
    "i dzieląc prawą stronę równania (13) przez $m$ możemy (stała nie zmienia szukania maksimum)  równanie (5) zapisać jako\n",
    "$$\n",
    "\\hat{\\theta} = arg \\ \\max_{\\theta} E_{x \\sim \\hat{p}_{data}} log(p_{model}(x;\\theta)\n",
    "$$\n",
    "\n",
    "Widać tu lepiej, że istotą największej wiarygodności jest doprowadzenie rozkładu modelu możliwie blisko rozkładowi  empirycznemu danych szkoleniowych. Jest to oczywiście słabsze żądanie niż \n",
    "optymalne zbliżenie rozkładu modelu do rzeczywistego rozkładu $p_{data}(x)$, ale niczego poza próbką danych nie posiadamy. \n",
    "\n",
    "Tak zdefiniowane zadanie można przeformułować do postaci jawnie pokazującej rozbieżność informacyjną pomiędzy rozkładem empirycznym danych szkoleniowych  i rozkładem modelu. Służy do tego tzw. \\textit{ dywergencja Kullbacka-Leiblera}, w tym przypadku mająca postać:\n",
    "$$\n",
    "d_{KL}(p_{model}, \\hat{p}_{data}) = E_{x \\sim \\hat{p}_{data}} \\left(log(\\hat{p}_{data}(x) - log(p_{model}(x;\\theta)\\right)\n",
    "$$\n",
    "Zadanie (7) jest w tym przypadku równoważne minimalizacji dywergencji Kullbacka-Leiblera według parametru $\\theta$.  Równanie (8) po rozpisaniu przyjmuje postać\n",
    "$$\n",
    "d_{KL}(p_{model}, \\hat{p}_{data}) = \\sum_{i=1}^m \\hat{p}_{data}(x_i)\\,log(\\hat{p}_{data}(x_i) - \\sum_{i=1}^m \\hat{p}_{data}(x)\\,log(p_{model}(x_i;\\theta),\n",
    "$$\n",
    "zatem minimalizacja dywergencji Kullbacka-Leiblera według parametru $\\theta$ oznacza minimalizację drugiego składnika prawej strony równania (9). Ostatecznie, maksymalizacja wiarygodności oznacza minimalizację wielkości \n",
    "$$\n",
    "-E_{x \\sim \\hat{p}_{data}} log(p_{model}(x;\\theta).\n",
    "$$\n",
    "\n",
    "\n",
    "Pierwszy składnik prawej strony równania (9) to definicyjnie ujemna entropia informacyjna $H(\\hat(p)_{data})$. Zatem równanie (9) można zapisać jako\n",
    "$$\n",
    "-E_{x \\sim \\hat{p}_{data}} log(p_{model}(x;\\theta)) = H(\\hat{p}_{data}) + d_{KL}(p_{model}, \\hat{p}_{data}).\n",
    "$$\n",
    "Wyrażenie z lewej strony byłoby równe entropii $H(\\hat{p}_{data})$, gdyby rozkład $p_{model}$ był równy rozkładowi $\\hat{p}_{data}$. Zatem dywergencję Kullbacka-Leiblera  można interpretować jako miarę zaburzenia informacji, którą wnosi zastosowanie niedokładnego rozkładu  $p_{model}$ w miejsce  rzeczywistego   rozkładu  $\\hat{p}_{data}$. Wyjaśnia to dlaczego wyrażenie \n",
    "$-E_{x \\sim \\hat{p}_{data}} log(p_{model}(x;\\theta))$ nazywane jest \\textit{entropią krzyżową} (czyli w istocie 'informacją krzyżową'). \\\\\n",
    "\n",
    "\\noindent \\textbf{Konkluzja}: Zadanie maksymalizacji wiarygodności jest równoważne zadaniu minimalizacji entropii krzyżowej.\n",
    " \n",
    "\n",
    "Entropia krzyżowa jest naturalnym źródłem konstrukcji różnych funkcji straty:\n",
    "\\begin{enumerate}\n",
    "\\item Wybieramy jako klasę modelu zbiór rozkładów Gaussa, tzn. $\\theta = (\\mu,\\sigma)$, gdzie $\\mu$ jest wartością oczekiwaną rozkładu, a $\\sigma$ jego wariancją. Rozpatrujemy zbiór przykładów\n",
    "uczących $(x,y) = (x_i,y_i)_{i=1}^n$ oraz zakładamy, że wariancja $\\sigma$ danych szkoleniowych jest stała i że model aproksymuje wartość oczekiwaną rozkładu empirycznego danych szkoleniowych, \n",
    "tzn. $\\mu\\approx \\hat{y}(x,w)$. Wtedy \n",
    "\n",
    "$$\n",
    "p_{model}(y|x)= N(y;\\hat{y}(x,w),\\sigma^2) = \\frac{1}{2\\pi\\sigma^2}e^{\\frac{\\|y-\\hat{y}(x,w)\\|^2}{2\\sigma^2}}.\n",
    "$$  \n",
    "Zatem \n",
    "\n",
    "$$\n",
    "-E_{x,y \\sim \\hat{p}_{data}} log(p_{model}(x;\\theta))  = -\\frac{1}{m}\\sum_{i=1}^m log\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{\\|y_i-\\hat{y_i}(x_i,w)\\|^2}{2\\sigma^2}}\\right)   \n",
    "$$\n",
    "\n",
    "$$\n",
    "=-\\frac{1}{m}m\\,log\\left(\\frac{1}{2\\pi\\sigma^2}\\right) -\\frac{1}{m}\\sum_{i=1}^m log\\left(e^{-\\frac{\\|y_i-\\hat{y_i}(x_i,w)\\|^2}{2\\sigma^2}}\\right) \n",
    "$$\n",
    "$$\n",
    "=-log(1) + \\frac{1}{2}log(2\\pi) + log(\\sigma) -\\frac{1}{m}\\sum_{i=1}^m log\\left(e^{-\\frac{\\|y_i-\\hat{y_i}(x_i,w)\\|^2}{2\\sigma^2}}\\right) \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "=\\frac{1}{2}log(2\\pi) + log(\\sigma) +\\frac{1}{m}\\sum_{i=1}^m \\frac{\\|y_i-\\hat{y_i}(x_i,w)\\|^2}{2\\sigma^2} \n",
    "$$\n",
    "$$\n",
    "=\\frac{1}{2}log(2\\pi) + log(\\sigma) +\\frac{1}{2m\\sigma^2}\\sum_{i=1}^m \\|y_i-\\hat{y_i}(x_i,w)\\|^2\n",
    "$$\n",
    "Widać zatem, że minimalizacja takiej wielkości względem parametrów modelu, którymi w tym przypadku są wagi $w$ odpowiada minimalizacji ostatniego składnika. Wynika z tego, że minimalizacja \n",
    "entropii krzyżowej pomiędzy rozkładem empirycznym danych szkoleniowych i rozkładem Gaussa  jest równoważna minimalizacji błędu średniokwadratowego. W szczególności oznacza to , że regresja liniowa \n",
    "jest metodą maksymalizującą wiarygodność. Dodatkowym wnioskiem jest tu uwaga, że sieć aproksymująca średnią z danych szkoleniowych (wartość oczekiwana jest przecież średnią) nie wymaga dla zadania minimalizacji funkcji kosztu żadnych metod optymalizacji (typu metody gradientowe), gdyż jak wiadomo minimum jest obliczalne przez zwykły układ równań. \n",
    "\n",
    "Zwróćmy w tym miejscu jeszcze uwagę na ciekawe cechy estymatora średniokwadratowego (ozn. MSE), a mianowicie na jego zgodność i obciążoność. \n",
    "\n",
    "$$\t\n",
    "MSE(\\theta,\\theta_m) = E((\\theta-\\theta_m)^2) = E(\\theta^2) + E(\\theta_m^2) - 2*E(\\theta*\\theta_m)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Bias(\\theta_m) = E(\\theta) - E(\\theta_m)  \n",
    "$$\n",
    "\n",
    "$$\n",
    "(Bias(\\theta_m))^2 = (E(\\theta) - E(\\theta_m))^2 = (E(\\theta))^2 +  (E(\\theta_m))^2 - 2* E(\\theta)*E(\\theta_m)\n",
    "$$\n",
    "\t\n",
    "$$\n",
    "Var(\\theta_m) = E((\\theta_m-E(\\theta_m))^2)= E(\\theta_m^2) + (E(\\theta_m))^2 - 2*(E(\\theta_m))^2 =\n",
    "$$\n",
    "\n",
    "$$\n",
    "= E(\\theta_m^2) - (E(\\theta_m))^2\n",
    "$$\n",
    "\n",
    "Stąd \n",
    "\t\n",
    "$$\n",
    "(Bias(\\theta_m))^2 + Var(\\theta_m) =\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (E(\\theta))^2 +  (E(\\theta_m))^2 - 2* E(\\theta)*E(\\theta_m) + E(\\theta_m^2) - (E(\\theta_m))^2 =\n",
    "$$\n",
    "\n",
    "$$  \n",
    "= (E(\\theta))^2  - 2* E(\\theta)*E(\\theta_m) + E(\\theta_m^2) = MSE(\\theta,\\theta_m)\n",
    "$$\n",
    "\t \n",
    "\t \n",
    "Zatem $MSE(\\theta,\\theta_m)$ jest estymatorem jakości modelu $\\theta_m$ sumującym w sobie obciążenie i wariancję $\\theta_m$. \n",
    "\n",
    "\n",
    "Obciążoność modelu pokazuje, jak daleko, średnio, predykcja estymatora odchyla się od rzeczywistej średniej.\n",
    "Wariancja modelu odzwierciedla wrażliwość predykcji na zbiór uczący. Zarówno obciążoność, jak i wariancja  zależą rownież od konkretnego rozkładu, do którego stosowany jest model.\n",
    "\n",
    "W wielu modelach regresji występuje parametr kontrolujący ich elastyczność\n",
    "(lub złożoność). Na przykład elastyczność sieci neuronowych zależy od\n",
    "liczba ukrytych warstw i liczby znajdujących się w nich neuronów. Elastyczność\n",
    "klasyfikatora k-najbliższych sąsiadów zależy od liczby k. Im bardziej elastyczny\n",
    "model, tym większa jest przestrzeń możliwych do rozpatrzenia funkcji . Takie modele\n",
    "mają mniejszą obciążoność, ale większą wariancję. Stąd pojawia się problem ze znalezieniem\n",
    "optymalnej wartości elastycznosci, która daje optymalną równowagę między obciążonością i\n",
    "wariancją. \n",
    "\n",
    "Poniższy rysunek pokazuje reprezentacje czterech  różnych scenariuszy. Okręgi\n",
    "reprezentują poziomy funkcji straty. Mniejsze kółka oznaczają mniejszą jej wartość. Każdy zbiór  kropek odpowiada innemu zestawowi treningowemu. Wysoka obciążoność oznacza duży błąd, wysoka wariancja nie gwarantuje niskiego błędu.\n",
    "\n",
    "![bias_variance](nn_images\\bias_variance_reg.png)\n",
    "\n",
    "\\item Rozpatrzmy model z klasy rozkładów Bernoulli'ego, czyli dwuelementowego zbioru wartości, konwencjonalnie 0 lub 1. Puentą przykładu wstępnego i późniejszych uwag o potrzebie wygładzania funkcji aktywacji dla alogrytmów gradientowych było wprowadzenie w takiej sytuacji funkcji logistycznej (ozn. $\\sigma$) jako funkcji aktywacji. W przypadku klasyfikacji binarnej z wartościami 0,1, oprócz gładkości potrzebujemy również zakresu wartości [0,1], co jest zapewnione w konstrukcji funkcji logistycznej. Ponadto można ją zdefiniować na dowolnej dziedzinie, więc w szczególności takiej, na której całka będzie równa 1, co pozwala taką funkcję traktować jako gęstość prawdopodobieństwa (w klasyfikacji binarnej wartość 0.5 jest używana jako próg klasyfikujący). W efekcie \n",
    "$\\hat{y}(x)= \\sigma(w^Tx+b)$ oraz\n",
    "\n",
    " $$\n",
    "-E_{x,y \\sim \\hat{p}_{data}} log(p_{model}(x;\\theta))  = -\\frac{1}{m}\\sum_{i=1}^m y_i log(\\hat{y_i})+  (1- y_i)log(1-\\hat{y_i}).\n",
    "$$\n",
    "Tak skonstruowaną funkcję starty nazywamy regresją logistyczną\\footnote{Niektórzy autorzy zwracają uwagę na dziwność tej nazwy, gdyż stosuje się ją do zagadnienia klasyfikacyjnego} i \n",
    "stosujemy ją w do klasyfikacji binarnej w parze z funkcją logistyczną jako funkcją aktywacji.\n",
    "\\item W przypadku klasyfikacji wielowartościowej uogólniamy procedurę z poprzedniego punktu. Rozpatrujemy\n",
    "cały wektor wartości $(y_i)_{i=1}^m$  i  definiujemy na nim  funkcję aktywacji  (tzw. \\textit{softmax}) zwracającą wektor takiego samego rozmiaru, w który i-ta składowa ma postać:\n",
    "$$\n",
    "p(y_i) = \\frac{e^{x_i}}{\\sum_{k=1}^me^{x_k}}.\n",
    "$$\n",
    "Wektor taki może być traktowany jako wektor prawdopodobieństwa, co implikuje, że funkcja straty wyprowadzona z minimalizacji entropii krzyżowej jest identyczna jak w przypadku klasyfikacji binarnej.\n",
    "\\end{enumerate}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorytmy optymalizacji\n",
    "\n",
    "Kilka elementarnych pojęć teorii optymalizacji związanych z algorytmem największego spadku znajduje się na stronie [wstęp do optymalizacji](optymalizacja1.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
